{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2, os, joblib\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load HAAR face classifier\n",
    "face_classifier = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "# Load functions\n",
    "def face_extractor(img):\n",
    "    # Function detects faces and returns the cropped face\n",
    "    # If no face detected, it returns the input image\n",
    "    \n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_classifier.detectMultiScale(gray, 1.3, 5)\n",
    "    \n",
    "    if faces == ():\n",
    "        return None\n",
    "    \n",
    "    # Crop all faces found\n",
    "    for (x,y,w,h) in faces:\n",
    "        cropped_face = img[y:y+h, x:x+w]\n",
    "\n",
    "    return cropped_face\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Kev:\n",
    "    def file(self, person_name):\n",
    "        train_dir = Path('C://Users//kevin//Documents//Project//Task_4//Train//')\n",
    "        self.A = train_dir / person_name\n",
    "        os.mkdir(self.A)\n",
    "        test_dir = Path('C://Users//kevin//Documents//Project//Task_4//Validation//')\n",
    "        self.B = test_dir / person_name\n",
    "        os.mkdir(self.B)\n",
    "\n",
    "    def capture(self):\n",
    "        # Initialize Webcam\n",
    "        cap = cv2.VideoCapture(0)\n",
    "        count = 0\n",
    "\n",
    "\n",
    "        # Collect 100 samples of your face from webcam input\n",
    "        while True:\n",
    "\n",
    "            ret, frame = cap.read()\n",
    "            if face_extractor(frame) is not None:\n",
    "                count += 1\n",
    "                face = cv2.resize(face_extractor(frame), (200, 200))\n",
    "                face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "                # Save file in specified directory with unique name for train and test Each\n",
    "\n",
    "                file_name_train_path = str(self.A)+ '/' + str(count) + '.jpg'\n",
    "                cv2.imwrite(file_name_train_path, face)\n",
    "                file_name_test_path = str(self.B) + '/' + str(count) + '.jpg'\n",
    "                cv2.imwrite(file_name_test_path, face)\n",
    "\n",
    "                # Put count on images and display live count\n",
    "                cv2.putText(face, str(count), (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2)\n",
    "                cv2.imshow('Face Cropper', face)\n",
    "\n",
    "            else:\n",
    "                print(\"Face not found\")\n",
    "                pass\n",
    "\n",
    "            if cv2.waitKey(1) == 13 or count == 100: #13 is the Enter Key\n",
    "                break\n",
    "\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()      \n",
    "        print(\"Collecting Samples Complete\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Learning():\n",
    "    import cv2\n",
    "    from pathlib import Path\n",
    "    from keras.models import Model, Sequential\n",
    "    from keras.preprocessing import image\n",
    "    from keras.applications import Xception\n",
    "    from keras.preprocessing.image import ImageDataGenerator\n",
    "    from keras.layers import Dense, Conv2D, GlobalMaxPooling2D, Dropout, Activation, Flatten\n",
    "    from keras.optimizers import RMSprop\n",
    "\n",
    "\n",
    "    img_rows, img_cols = 224, 224 \n",
    "    model = Xception(weights = 'imagenet', \n",
    "                     include_top = False, \n",
    "                     input_shape = (img_rows, img_cols, 3))\n",
    "\n",
    "\n",
    "    # Here we freeze the last 4 layers \n",
    "    # Layers are set to trainable as True by default\n",
    "    for layer in model.layers:\n",
    "        layer.trainable = False\n",
    "    model.summary()\n",
    "\n",
    "\n",
    "    def add(BottomModel, Class):\n",
    "        top_model = BottomModel.output\n",
    "        top_model = GlobalMaxPooling2D()(top_model)\n",
    "        top_model = Dense(1024,activation='relu')(top_model)\n",
    "        top_model = Dense(1024,activation='relu')(top_model)\n",
    "        top_model = Dense(512,activation='relu')(top_model)\n",
    "        top_model = Dense(Class,activation='softmax')(top_model)\n",
    "        return top_model\n",
    "\n",
    "\n",
    "    Class = 2\n",
    "    top = add(model, Class)\n",
    "    model = Model(inputs = model.input, outputs = top)\n",
    "\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "\n",
    "    #Image Data Generator\n",
    "    train_datagen = ImageDataGenerator(\n",
    "            rescale=1./255,\n",
    "            shear_range=0.2,\n",
    "            zoom_range=0.2,\n",
    "            horizontal_flip=True)\n",
    "    validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "    test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "            'C://Users//kevin//Documents//Project//Task_4//Train//',\n",
    "            target_size=(img_rows, img_cols),\n",
    "            batch_size=64,\n",
    "            class_mode='categorical')\n",
    "    validation_generator = validation_datagen.flow_from_directory(\n",
    "            'C://Users//kevin//Documents//Project//Task_4//Validation//',\n",
    "            target_size=(img_rows, img_cols),\n",
    "            batch_size=64,\n",
    "            class_mode='categorical')\n",
    "\n",
    "\n",
    "    model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "    #validation_steps < validation_dataset_size / batch_size\n",
    "    model.fit(\n",
    "            train_generator,\n",
    "            epochs=5,\n",
    "            validation_data=validation_generator)\n",
    "\n",
    "\n",
    "    model.save('Face_Detector.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = Kev()\n",
    "ans=True\n",
    "while ans:\n",
    "    print(\"\"\"\n",
    "    1. Add Face Image Data\n",
    "    2. Train Model\n",
    "    3. Test Model\n",
    "    4.Exit/Quit\n",
    "    \"\"\")\n",
    "    ans=input(\"What would you like to do? \")\n",
    "    if ans==\"1\":\n",
    "        k.file(person_name = input(\"Name?\"))\n",
    "        k.capture()\n",
    "        print(\"\\nFace Data Added\")\n",
    "    elif ans==\"2\":\n",
    "        Learning()\n",
    "        print(\"\\nModel Trained\")\n",
    "    elif ans==\"3\":\n",
    "        model = load_model('Face_Detector.h5')\n",
    "        print(\"\\n Student Record Found\")\n",
    "    elif ans==\"4\":\n",
    "      print(\"\\n Goodbye\") \n",
    "      ans = None\n",
    "    else:\n",
    "       print(\"\\n Not Valid Choice Try again\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Yay, the file exists!') if k.A.exists() and k.B.exists() else print(\"Oops, file doesn't exist!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.load('Face Detector.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
